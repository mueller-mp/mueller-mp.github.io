---
title: "How to rain your ViT for OOD Detection"
collection: publications
permalink: /publication/2024-05-21-OODVITS
excerpt: 'VisionTransformers have been shown to be powerful out-of-distribution detectors for ImageNet-scale settings when finetuned from publicly available checkpoints, often outperforming other model types on popular benchmarks. In this work, we investigate the impact of both the pretraining and finetuning scheme on the performance of ViTs on this task by analyzing a large pool of models. We find that the exact type of pretraining has a strong impact on which method works well and on OOD detection performance in general. We further show that certain training schemes might only be effective for a specific type of out-distribution, but not in general, and identify a best-practice training recipe.'
date: 2024-05-21
venue: 'ICLR workshop on Responsible and Reliable Foundation Models'
paperurl: 'https://arxiv.org/abs/2405.17447'
citation: 'Maximilian Müller and Matthias Hein (2024) “How to rain your ViT for OOD Detection”,   <i> ICLR 2024 R2FM Workshop</i>'
---
VisionTransformers have been shown to be powerful out-of-distribution detectors for ImageNet-scale settings when finetuned from publicly available checkpoints, often outperforming other model types on popular benchmarks. In this work, we investigate the impact of both the pretraining and finetuning scheme on the performance of ViTs on this task by analyzing a large pool of models. We find that the exact type of pretraining has a strong impact on which method works well and on OOD detection performance in general. We further show that certain training schemes might only be effective for a specific type of out-distribution, but not in general, and identify a best-practice training recipe.

[Download paper here](https://arxiv.org/abs/2405.17447)

Recommended citation: Maximilian Müller and Matthias Hein (2024) “How to rain your ViT for OOD Detection”,   <i> ICLR 2024 R2FM Workshop</i>
